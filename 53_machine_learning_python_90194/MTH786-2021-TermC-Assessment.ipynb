{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affiliated-smith",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d75012d578582ffd16a89afe6011db4",
     "grade": false,
     "grade_id": "Header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` and that you delete any **raise NotImplementedError()** once you have filled in your code. Enter your student identifier below:\n",
    "\n",
    "Start by filling in your Name and student ID below. **DO IT NOW**. Save this Jupyter Notebook with the name *MTH786P_surname_ID.ipynb*, where instead of *surname* and *ID* you write your surname and your student ID number.\n",
    "    \n",
    "Use the available cells to introduce the code. You can add additional cells if needed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-labor",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba909f874dc10cc2984f42a2cadbb40a",
     "grade": false,
     "grade_id": "StudentID",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "STUDENT NAME = \"\"\n",
    "    \n",
    "STUDENT ID = \"\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-assumption",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43dd8db4fd9c0635712638ead0af981f",
     "grade": false,
     "grade_id": "cell-443c044d8f383c41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# MTH786U/P assessment template (Sem C, 2020/2021)\n",
    "\n",
    "This is the coding template for the final project assessment part of MTH786U/P in Semester A of 2020/2021.\n",
    "\n",
    "The goal of this assessment is to classify fashion images from the [Fashion MNIST database](https://www.kaggle.com/zalando-research/fashionmnist) and to present your results in a written report (at most 8 pages). The assessment is formed of three parts: 1) filling in the missing parts of this Jupyter notebook, 2) applying learned concepts from this notebook and the module MTH786 in general to the Fashion MNIST classification problem, and 3) presenting your results in a written report (written in $\\LaTeX$). \n",
    "\n",
    "Author: [Mihail Poplavskyi](mailto:m.poplavskyi@qmul.ac.uk),[Martin Benning](mailto:m.benning@qmul.ac.uk)\n",
    "\n",
    "Date: 16.08.2021\n",
    "\n",
    "Follow the instructions in this template in order to complete the first part of your assessment. Please only modify cells where you are instructed to do so. Failure to comply may result in unexpected errors that can lead to mark deductions. We load the Numpy and Matplotlib libraries. Please do not add any additional libraries here but at a later stage if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-belfast",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6cfb2d4b677655c61026e3a51a51a6f",
     "grade": false,
     "grade_id": "cell-b85ab67935d9efb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#these modules are needed for a visualisation only\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-allocation",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c718b66d5b5821cd2ad473e839afd5de",
     "grade": false,
     "grade_id": "cell-7eb658dc4ba00637",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Binary logistic regression\n",
    "\n",
    "For the first part of your final assessment you are required to implement the logistic regression model for binary classification problems as introduced in the lectures. Following up on what you have learned in the lectures and tutorials, complete the following tasks.\n",
    "\n",
    "Write a function ***logistic_function*** that takes an argument named _inputs_ and returns the output of the $\\tanh(x)$ sigmoid function, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\sigma(x): = \\tanh\\left(\\frac{x}{2}\\right) = \\frac{\\mathrm{e}^{x/2}-\\mathrm{e}^{-x/2}}{\\mathrm{e}^{x/2}+\\mathrm{e}^{-x/2}} \\, ,\n",
    "\\end{align*}\n",
    "\n",
    "applied to the input. Here $x$ is the mathematical notation for the argument _inputs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-substitute",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6af3fac17c9264b64962a0b23afc245c",
     "grade": false,
     "grade_id": "cell-c0ec3d26c7270b06",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def logistic_function(inputs):    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-ribbon",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "523fe7c3cabc81cdbce5f2e6581e7895",
     "grade": false,
     "grade_id": "cell-54093a6a8236bd83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your function with the following unit tests. Passing this test will be awarded with **2 marks**. Please note that not all unit tests are visible to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-partner",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "097a2e17b0b02bd2133fd47df455940b",
     "grade": true,
     "grade_id": "cell-c374ffad259c5f2b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_array_almost_equal, assert_array_equal\n",
    "test_inputs = np.array([[0], [np.log(25)], [-6], [np.log(9)], [2]])\n",
    "assert_array_almost_equal(logistic_function(test_inputs), np.array([[0], [12/13], [-0.99505475368], \\\n",
    "                            [4/5], [(np.exp(2)-1)/(1 + np.exp(2))]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-nepal",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc9b3d53dc8b862bee1085d6edda3824",
     "grade": false,
     "grade_id": "cell-3420d37b7b721660",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Binary classification problem with $\\tanh(x)$ sigmoid function**  \n",
    "Before you proceed with the binary classification implementation you may wish to read and digest the following theoretical findings. \n",
    "\n",
    "Let us consider a supervised binary logistic regression problem on a training data $\\left\\{x^{(i)}, y_i\\right\\}_{i=1}^s$, where for any $i=\\overline{1,s}$ one has $x^{(i)}\\in\\mathbb{R}^d$ and $y_i \\in \\left\\{-1,1\\right\\}$. One could think of solving classification problems with the same tools that we have used for tackling regression problems, i.e. by introducing the prediction function $f(x;w)$ and then by thresholding the function output. We can define the following probabilities for the events that the output $f(x;w)$ belongs the\n",
    "class with class label negative one or the class with class label one\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\rho\\left(-1\\rvert \\mathbf{x},\\mathbf{w} \\right) &= \\frac{1}{2}\\left(1-\\sigma\\left(f\\left(\\mathbf{x},\\mathbf{w}\\right)\\right)\\right),\\\\\n",
    "\\rho\\left(1\\rvert \\mathbf{x},\\mathbf{w} \\right) &= \\frac{1}{2}\\left(1+\\sigma\\left(f\\left(\\mathbf{x},\\mathbf{w}\\right)\\right)\\right),\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\sigma\\left(x\\right) = \\tanh\\left(\\frac{x}{2}\\right)$ as before. The above can be equivalently written as\n",
    "$$\n",
    "\\rho\\left(y\\rvert \\mathbf{x},\\mathbf{w} \\right) = \\frac{1}{2}\n",
    "\\left(1+y\\sigma\\left(f\\left(\\mathbf{x},\\mathbf{w}\\right)\\right)\\right),\n",
    "$$\n",
    "or \n",
    "$$\n",
    "\\rho\\left(y\\rvert \\mathbf{x},\\mathbf{w} \\right) = \n",
    "\\frac{1}{1+\\mathrm{e}^{-yf\\left(\\mathbf{x},\\mathbf{w}\\right)}}\n",
    "$$\n",
    "for $y = \\pm 1$. The corresponding optimization problem, obtained via the maximization of likelihood method, takes the form\n",
    "$$\n",
    "\\hat w = \\arg\\min\\limits_{w} L\\left(\\mathbf{w}\\right),\n",
    "\\mbox{where }\n",
    "L\\left(\\mathbf{w}\\right) = \n",
    "\\sum\\limits_{i=1}^s \n",
    "\\log\\left(\n",
    "1+\\mathrm{e}^{-y_i f\\left(\\mathbf{x}^{(i)},\\mathbf{w}\\right)}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "If the prediction function $f\\left(\\mathbf{x},\\mathbf{w}\\right)$ depends on a scalar product $\\left\\langle \\mathbf{x}, \\mathbf{w}\\right\\rangle$ only, then the gradient of $L\\left(\\mathbf{w}\\right)$ is equal to\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} L\\left(\\mathbf{w}\\right) = \n",
    "- \\sum\\limits_{i=1}^s y_i\\frac{\\mathrm{e}^{-y_if\\left(\\left\\langle \\mathbf{x}^{(i)},\\mathbf{w}\\right\\rangle\\right)}}{1+\\mathrm{e}^{-y_if\\left(\\left\\langle \\mathbf{x}^{(i)},\\mathbf{w}\\right\\rangle\\right)}}\\mathbf{x}^{(i)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-auditor",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c34daa3a0bbbf70d485c914ca4261ec2",
     "grade": false,
     "grade_id": "cell-ae509c771ea5fab3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For the next exercise, write two functions that implement the objective function for binary logistic regression as well as its gradient, as defined in the lecture notes. The function for the objective function is named **binary_logistic_regression_cost_function** and should take the NumPy arrays _data_matrix_, _weights_ and _outputs_ as arguments. Here, _data_matrix_ is supposed to be a polynomial basis matrix, while _weights_ denotes the vector of weight parameters and _outputs_ is the vector of binary outputs (with values in $\\{-1, 1\\}$). In order to generate a polynomial basis matrix, fill in the function **polynomial_basis**. You can follow the [solution](https://qmplus.qmul.ac.uk/mod/resource/view.php?id=1619573) of [Assignment 4](https://qmplus.qmul.ac.uk/mod/resource/view.php?id=1619572) or use your own version, as long as it is consistent with the function header specified in the next cell and with the requested output. Subsequently, write a method **binary_logistic_regression_gradient** that takes the same inputs as **binary_logistic_regression_cost_function** and computes the gradient of the binary logistic regression cost function as defined in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-premium",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fad9ec994bb13523f9b79d6b6faacb8",
     "grade": false,
     "grade_id": "cell-f36e875fbf379c85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def polynomial_basis(inputs, degree=1):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def binary_logistic_regression_cost_function(data_matrix, weights, outputs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def binary_logistic_regression_gradient(data_matrix, weights, outputs): \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-canyon",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92a830e631aad6a12a08e3c261d51b92",
     "grade": false,
     "grade_id": "cell-d49a2930f97d5e81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After writing Python functions for the binary logistic regression cost function and its gradient, fill in the following notebook functions for the implementation of a gradient descent method. For the first function it is acceptable to follow the solution of [Assignment 5](https://qmplus.qmul.ac.uk/mod/resource/view.php?id=1625774), or to use your own version if is consistent with function header and output. For the second gradient descent function named **gradient_descent_v2**, modify the gradient descent method to include a stopping criterion that ensures that gradient descent stops once\n",
    "\n",
    "\\begin{align*}\n",
    "\\| \\mathbf{w}^{(k+1)} -  \\mathbf{w}^{(k)}\\| \\leq \\text{tolerance}\n",
    "\\end{align*}\n",
    "\n",
    "is satisfied. Here $\\mathbf{w}^{(k)}$ is the mathematical representations of the weight vector _weights_, at iteration $k$. The parameter _tolerance_ is a non-negative threshold that controls the Euclidean norm of the distance between the weights evaluated at consecutive iterations. The function **gradient_descent_v2** takes the arguments _objective_, _gradient_, _initial_weights_, _step_size_, _no_of_iterations_, _print_output_ and _tolerance_. The arguments _objective_ and _gradient_ are functions that can take (weight-)arrays as arguments and return the scalar value of the objective, respectively the array representation of the corresponding gradient. The argument _initial_weights_ specifies the initial value of the variable over which you iterate. The argument _step_size_ is the gradient descent step-size parameter, the argument _no_of_iterations_ specifies the maximum number of iterations, _print_output_ determines after how many iterations the function produces a text output and _tolerance_ controls the distance between the weights evaluated at consecutive iterations described in the equation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-transport",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8168e28ee56ab746330c1d0dfe452c0d",
     "grade": false,
     "grade_id": "cell-5b6904e54781c828",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(objective, gradient, initial_weights, step_size=1, no_of_iterations=100, print_output=10):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def gradient_descent_v2(objective, gradient, initial_weights, step_size=1, no_of_iterations=100, \\\n",
    "                        print_output=10, tolerance=1e-5):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-healthcare",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e38fd9ebc1987590cfa4c6231448f27",
     "grade": false,
     "grade_id": "cell-1449fe1de98be0d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following cell, write a function **standardise** that standardises the columns of a two-dimensional NumPy array _data_matrix_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-appliance",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15b55a07d336a2bbb70b683ba8f8f9fe",
     "grade": false,
     "grade_id": "cell-708b05085a2928da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def standardise(data_matrix):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-teacher",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e58d65f9e02f048e2f673b3c09bb46b",
     "grade": false,
     "grade_id": "cell-5f58501d82adf8a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your results with the following cell. A total of **3 marks** will be awarded if your function passes the following standard tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-effectiveness",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc3b5bd0cebf6d99cd731db52c59bcd7",
     "grade": true,
     "grade_id": "cell-243a269907a9f920",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_matrix = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "assert_array_almost_equal(standardise(test_matrix), np.array([[-1.22474487, -1.22474487], \\\n",
    "                            [0, 0],[1.22474487, 1.22474487]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-afternoon",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a32e4cfb4770cce68f9d940c9a45fe87",
     "grade": false,
     "grade_id": "cell-4b504adf8e187acb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To train a simple binary classifier, you require some data. The following cell calls a function that allows you to load the [titanic dataset](https://www.kaggle.com/c/titanic/) that was mentioned in our course. The data consists 891 rows. Each row represents a passenger and contains the following information:\n",
    "- Whether the passenger has survived (survival = 1) or not (survival = -1)\n",
    "- The passenger's cabin class (integer number from 1 to 3)\n",
    "- The passenger's sex (0 for male and 1 for female)\n",
    "- The passenger's age (half-integer number)\n",
    "- The number of passenger's siblings/spouses on the ship (integer number)\n",
    "- A number of the passenger's parents/children on the ship (integer number)\n",
    "- A price of the passenger's ticket (floating point number)\n",
    "- Port of the passenger's embarkation encoded in three columns: whether the port is Southampton (0 or 1), whether the port is Queenstown (0 or 1), whether the port is Cherbourg (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-judgment",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65d902522d4f2a3de7fc2d473e3f091a",
     "grade": false,
     "grade_id": "cell-d838218d9a6d3a79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from data_loader import load_titanic_train_data\n",
    "data, survival = load_titanic_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-draft",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0cc3263eddf5119f5449b8e89455f72",
     "grade": false,
     "grade_id": "cell-a83caf841c5cf637",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "titanic_full_data = pd.DataFrame({'Survival':survival, \\\n",
    "                           'Age': data[:,0], \\\n",
    "                           'Fare':data[:,1], \\\n",
    "                           'ParCh':data[:,2], \\\n",
    "                           'Class':data[:,3], \\\n",
    "                           'Sex':data[:,4], \\\n",
    "                           'SibSp':data[:,5],\\\n",
    "                           'PortS':data[:,6],\\\n",
    "                           'PortQ':data[:,7],\\\n",
    "                           'PortC':data[:,8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-ceiling",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e1d97c9631398d82e49329b61c0ff91",
     "grade": false,
     "grade_id": "cell-659cdb1595960f06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(titanic_full_data, \\\n",
    "             hue=\"Survival\", \\\n",
    "             markers = [\"s\", \"o\"], \\\n",
    "             palette = {-1:\"r\", 1:\"g\"},\\\n",
    "            kind = 'scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-thanksgiving",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d77715376c0c970ccfdb719a2080a438",
     "grade": false,
     "grade_id": "cell-f8b55d59ac7ade9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following cell, write code that initialises a polynomial data matrix _data_matrix_ of degree one with the standardised inputs formed from the passenger_class, passenger_sex, passenger_age,  passenger_siblings_spouses, passenger_parents_children, ticket_fare and embarkation_port arrays of the dataset. Define an objective function _objective_ with argument _weights_ based on the **binary_logistic_regression_cost_function** with fixed arguments _data_matrix_ and _survival_. Repeat the same exercise to create a function _gradient_ based on **binary_logistic_regression_gradient**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-rover",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ac3532166dbf9b8093acb8e781ae15e",
     "grade": false,
     "grade_id": "cell-f52f207e06cfd8cc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-pathology",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "123147a07d777ffc8bcdeaa34ff36948",
     "grade": false,
     "grade_id": "cell-1abdda4c5a21c883",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Call gradient descent with the following cell to compute _optimal_weights_ for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-tutorial",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e161409b17f132da397e0820ce7e3d86",
     "grade": false,
     "grade_id": "cell-f05dc0efb7a2f2ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(data_matrix.shape[1])\n",
    "optimal_weights, objective_values = gradient_descent(objective, gradient, initial_weights, \\\n",
    "                                    step_size=3.9/(np.linalg.norm(data_matrix, 2) ** 2), \\\n",
    "                                    no_of_iterations=20000, print_output=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-casino",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51da11a5b646cf5bf206ff600237e96f",
     "grade": false,
     "grade_id": "cell-b9602869e726ef17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A correct result of your gradient-descent-based logistic regression strategy will be awarded **4 marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-machine",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92d1d521f2791196ac6869c7853b733b",
     "grade": true,
     "grade_id": "cell-14af5b0cd1362821",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The optimal weights are w = {w}.T with objective value L(w) = {o}.\".format(w = optimal_weights.T, \\\n",
    "        o=objective_values[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-bumper",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ae90484d485b6612b63be5a48bda69c",
     "grade": false,
     "grade_id": "cell-97eb56a7f5f4a80b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write two functions **prediction_function** and **classification_accuracy** that turn your predicitons into classification results and that compare how many labels have been classified correctly. The function **prediction_function** takes the arguments _data_matrix_ and _weights_ as inputs and returns a vector of class labels with binary values in $\\{-1, 1\\}$ as its output. The function **classification_accuracy** takes two inputs _true_labels_ and _recovered_labels_ and returns the percentage of correctly classified labels divided by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-standing",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4269599125b5f49de2480c1060239810",
     "grade": false,
     "grade_id": "cell-19822dd526ca80d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def prediction_function(data_matrix, weights):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def classification_accuracy(true_labels, recovered_labels):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-intelligence",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5897186b1ab31358fdd7c85c40e683b1",
     "grade": false,
     "grade_id": "cell-1b1af2fa2ade17f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The correct classification accuracy is awarded **4 marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-fundamental",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "693b55ed57358e7a209c99318e811399",
     "grade": true,
     "grade_id": "cell-889604c74ee80aad",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The classification accuracy for the training set is {p} %.\".format(p = 100 * \\\n",
    "        classification_accuracy(survival, prediction_function(data_matrix, optimal_weights))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-introduction",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfef1227a48c9efa1bb63c58f53ca47f",
     "grade": false,
     "grade_id": "cell-e9f643b967d9c242",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now compare your result with the one produced by calling the _gradient\\_descent\\_v2_. Call version 2 of the gradient descent with the following cell to compute optimal_weights for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-leader",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd75f0f67c0be332d52dbe4e86e89685",
     "grade": false,
     "grade_id": "cell-6e5ac938fd19c07d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(data_matrix.shape[1])\n",
    "optimal_weights, objective_values = gradient_descent_v2(objective, gradient, initial_weights, \\\n",
    "                                    step_size=3.9/(np.linalg.norm(data_matrix, 2) ** 2), \\\n",
    "                                    no_of_iterations=100000, print_output=2000, tolerance = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-thunder",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce894c8ac71d696f0ad745c3a385cb66",
     "grade": false,
     "grade_id": "cell-685b133a3d675df9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-relative",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b69ee197612609ba04d832628139bfdb",
     "grade": true,
     "grade_id": "cell-58f77fddb3c5f27d",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The classification accuracy for the training set is {p} %.\".format(p = 100 * \\\n",
    "        classification_accuracy(survival, prediction_function(data_matrix, optimal_weights))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-candidate",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e736d698bb603e9ca70277ef94ac803e",
     "grade": false,
     "grade_id": "cell-df00ef7d61dfe1cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A correct result of your gradient-descent-based logistic regression strategy with cut-off will be awarded **4 marks**.  The total marks possible in this section are **17 marks**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-locator",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87beedce6a4242bdf7b01cac6704087a",
     "grade": false,
     "grade_id": "cell-fbd8c6d736dbd53f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Ridge logistic regression\n",
    "\n",
    "For the next part, modify the binary logistic regression problem to include a squared norm of the weights vector as a regularisation term, similar to ridge regression where we added a multiple of the squared Euclidean norm of the weights to the mean squared error. Write two functions **ridge_logistic_regression_cost_function** and **ridge_logistic_regression_gradient** that take the arguments _data_matrix_, _weight_vector_, _outputs_ and _regularisation_parameter_ as inputs. The function **ridge_logistic_regression_cost_function** returns the evaluation of the binary logistic regression cost function with its linear model being determined by the polynomial basis matrix _data_matrix_ and the weight vector _weight_vector_, plus _regularisation_parameter_ times the squared norm of _weight_vector_ divided by two. The function **ridge_logistic_regression_gradient** is supposed to compute the corresponding gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-conducting",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90bcf8a8bca22f54553095458373210d",
     "grade": false,
     "grade_id": "cell-d6b9f1de99bd6b6b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ridge_logistic_regression_cost_function(data_matrix, weights, outputs, regularisation_parameter):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def ridge_logistic_regression_gradient(data_matrix, weights, outputs, regularisation_parameter):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-rehabilitation",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d6c5ba7b563bc2480bb12a27f15453b",
     "grade": false,
     "grade_id": "cell-6281bae1920006b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Set your regularisation parameter _regularisation_parameter_ to the value 15 and define an objective function _objective_ as well as a gradient function _gradient_, both with argument _weight_vector_, for fixed _data_matrix_ and _outputs_ as from the titanic dataset that you have used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-dietary",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1fd951caf0c3f54f9cbe1a5a47bbaba",
     "grade": false,
     "grade_id": "cell-4b7d8aee0a9d0cad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-effort",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe8a85f3141e57f683e6b21b15a83077",
     "grade": false,
     "grade_id": "cell-8daba42ca8a35317",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your solution with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-buffalo",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9d376d1bcb5ad08ab5ae01a4182f027",
     "grade": false,
     "grade_id": "cell-0dd14035b8a5a6eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "initial_weight_vector = np.zeros(data_matrix.shape[1])\n",
    "ridge_weight_vector, ridge_objective_values = gradient_descent(objective, gradient, initial_weight_vector, \\\n",
    "                                    step_size=3.9/np.linalg.norm(data_matrix.T @ data_matrix + \\\n",
    "                                    regularisation_parameter * np.eye(data_matrix.shape[1]), 2), \\\n",
    "                                    no_of_iterations=20000, print_output=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-track",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba509ce39b6e397a6c7f78d9edd33332",
     "grade": false,
     "grade_id": "cell-a73b2a78355514d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The correct classification accuracy is awarded **4 marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-reminder",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5095dae0894cb6d1944d33505e97214",
     "grade": true,
     "grade_id": "cell-56290302e5f294a1",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The ridge regression classification accuracy with regularisation parameter {a}\".format(a = \\\n",
    "       regularisation_parameter), \"for the titanic training set is {p} %.\".format(p = 100 * \\\n",
    "        classification_accuracy(survival, prediction_function(data_matrix, ridge_weight_vector))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-manual",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5aba40392c9f9101518aa8261a0858d0",
     "grade": false,
     "grade_id": "cell-051511747ea8cfde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**K-fold validation and optimisation of hyperparameters**\n",
    "\n",
    "This is the last part of the binary classification part of the final assessment. In this part you will be asked \n",
    "to perform a grid search to optimise the classification accuracy of ridge binary logistic regression over the value of a hyperparameter _regularisation\\_parameter_. You are also asked to perform a K-fold cross validation when calculating the classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-shopper",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cd9bfdd392b471752e8c639897e66f9",
     "grade": false,
     "grade_id": "cell-4ccbb88df733a3cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a first exercise you are asked to implement a  K -fold cross validation strategy as introduced in the lectures. Write a function  **data_split** that takes arguments _data\\_matrix_, _outputs_  and  _chunks\\_number_  and splits the data randomly into  K = _chunks\\_number_ equal (or almost equal) chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-evolution",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05afbedcd3af2da02a0142510b1bba74",
     "grade": false,
     "grade_id": "cell-9f8dba66d6ff1d03",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def data_split(data_matrix, outputs, chunks_number):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-employee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2edff70a5d85ab29337c41fb424ea815",
     "grade": false,
     "grade_id": "cell-087cfdf506787f4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below you are given a function **K_fold_validation_error**  that takes arguments  _data\\_matrix_ ,  _outputs_ ,  _regularisation\\_parameter_ , _chunks\\_number_, and using the functions previously defined\n",
    "- splits the data into  _chunks\\_number_  chunks;\n",
    "- uses  K-1  chunks to compute the ridge regression weights  and the remaining set as the validation set  $S_v$  for the calculation of classification accuracy;\n",
    "- repeats the procedure for all choices of $K-1$ chunks combinations, and averages the result;\n",
    "- returns the average _average\\_weights_ and the corresponding _classiffication\\_accuracy_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-intellectual",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67d6d755dc91ffe3f2556ff90731c763",
     "grade": false,
     "grade_id": "cell-daf32603fe243901",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def K_fold_validation_error(data_matrix, outputs, regularisation_parameter,chunks_number):\n",
    "    \n",
    "    splited_data, splited_outputs = data_split(data_matrix, outputs, chunks_number)\n",
    "    \n",
    "    average_weights = np.zeros(data_matrix.shape[1])\n",
    "    \n",
    "    for validation_chunk in range(chunks_number):\n",
    "        \n",
    "        validation_data = splited_data[validation_chunk]\n",
    "        validation_ouputs = splited_outputs[validation_chunk]\n",
    "        \n",
    "        training_data = np.concatenate([splited_data[i] for i in range(chunks_number) if i!=validation_chunk], axis = 0)\n",
    "        training_output = np.concatenate ([splited_outputs[i] for i in range(chunks_number) if i!=validation_chunk], axis = 0)\n",
    "        \n",
    "        objective = lambda weights: \\\n",
    "            ridge_logistic_regression_cost_function (training_data, weights, training_output, regularisation_parameter)\n",
    "        gradient = lambda weights: \\\n",
    "            ridge_logistic_regression_gradient (training_data, weights, training_output, regularisation_parameter)\n",
    "        \n",
    "        initial_weight_vector = np.zeros(training_data.shape[1])\n",
    "        ridge_weight_vector, ridge_objective_values = gradient_descent_v2(objective, gradient, initial_weight_vector, \\\n",
    "                                    step_size=3.9/np.linalg.norm(training_data.T @ training_data + \\\n",
    "                                    regularisation_parameter * np.eye(training_data.shape[1]), 2), \\\n",
    "                                    no_of_iterations=10000, print_output=1001, tolerance = 1e-5)\n",
    "        \n",
    "        average_weights += ridge_weight_vector\n",
    "    \n",
    "    average_weights /= chunks_number\n",
    "    ridge_classification_accuracy = classification_accuracy(validation_ouputs, prediction_function(validation_data, average_weights))\n",
    "    \n",
    "    return average_weights, ridge_classification_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-oasis",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9e1232d6df03ce7b34fcd1c11d15b6c",
     "grade": false,
     "grade_id": "cell-2927650bc5450174",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the **K_fold_validation_error** function analyse the behaviour of the classification error as a function of _regularisation\\_parameter_. Consider the integer grid _[0,1,2,3,4,5,6,7,8,9,10]_, evaluate the classification error (using the K-fold cross validation method with K = 5) for all points of the grid and find such a value of regularisation parameter that maximises the classication accuracy on the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-canberra",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "444453b9e84bf6ade0557e7f327bb27a",
     "grade": false,
     "grade_id": "cell-89c569e005e7f803",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-chick",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e752570aba15d06ccb65c1282396c5ea",
     "grade": false,
     "grade_id": "cell-7aa91cdeae8f2d7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The correct classification accuracy is awarded **6 marks**. The total marks possible in this section are **10 marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-client",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b51d1c1685b431b2aaf8d8c5b0d4dd0",
     "grade": true,
     "grade_id": "cell-0577bb78ea667a35",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "max_classification_accuracy = np.argmax(classification_accuracy_grid)\n",
    "print(\"The classification accuracy of a ridge binary classification is maximised for regularisation parameter a  = {a}\".\\\n",
    "      format(a = alpha_grid[max_classification_accuracy]), \"and is equal to {p} %.\".\\\n",
    "      format(p = 100* classification_accuracy_grid[max_classification_accuracy]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-contemporary",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff18c0b8d518745351e55dd11c8b9766",
     "grade": false,
     "grade_id": "cell-786223bde2258454",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Multinomial logistic regression\n",
    "\n",
    "This concludes the binary classification part of the first part of the final assessment. We now move on to multinomial logistic regression for multi-class classfication problems. As a first exercise, implement the softmax function **softmax_function** as defined in the lectures. The function takes the NumPy array _argument_ as its main argument, but also has an optional _axis_ argument to determine across which array-dimension you apply the softmax operation. If this argument is not specified (or set to _None_), then the softmax operation is applied to the entire array. Make sure your function works at least for NumPy arrays _argument_ with arbitrary numerical values and dimension one or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-decline",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16ce15fefa0fc28571a24e4f9b01cc06",
     "grade": false,
     "grade_id": "cell-02b5be4e7748613d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax_function(argument, axis=None):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-cornell",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c633099b0007d279c729d48a23241730",
     "grade": false,
     "grade_id": "cell-cb763ffb3b8951ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your softmax function with the following cell. Passing this test is awarded with **4 marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-princess",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fab82ae8488fb584998e34071d829d4",
     "grade": true,
     "grade_id": "cell-b4c3a9a35caeb32a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "argument = np.array([[1.5], [0.3], [-3.7]])\n",
    "print(\"The softmax of {arg}.T is {out}.T.\".format(arg=argument.T, out=softmax_function(argument).T))\n",
    "assert_array_almost_equal(softmax_function(np.array([[1.5], [0.3], [-3.7]])), np.array([[0.76528029], \\\n",
    "                                                        [0.23049799], [0.00422172]]))\n",
    "assert_array_almost_equal(softmax_function(np.array([[1.5, 3], [0.3, -0.7], [-3.7, 2]]), axis=0), \\\n",
    "                          np.array([[0.76528029, 0.71807976], [0.23049799, 0.01775346], \\\n",
    "                                    [0.00422172, 0.26416678]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-albert",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb8839a40f70e60bea2fed14f106aa5c",
     "grade": false,
     "grade_id": "cell-2f05184eb794bf53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, write a function **one_hot_vector_encoding** that converts an NumPy array _labels_ with values in the range of $\\{0, K - 1\\}$ into so-called one-hot vector encodings. For example, for $K = 3$ and a label vector $\\text{labels} = \\left( \\begin{matrix} 2 & 0 & 1 & 2\\end{matrix} \\right)^\\top$, the output of **one_hot_vector_encoding(labels)** should be a two-dimensional NumPy array of the form\n",
    "\n",
    "\\begin{align*}\n",
    "\\left( \\begin{matrix} 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{matrix} \\right) \\, . \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-prerequisite",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcfb2a95ead73ce40923d31424aea594",
     "grade": false,
     "grade_id": "cell-6f4aa177d47a2793",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_vector_encoding(labels):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-letters",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99ceecc3d0a0d44d2cc54c3d6d2425e8",
     "grade": false,
     "grade_id": "cell-caba2e99d7123aad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your _one\\_hot\\_vector\\_encoding_ function with the following cell. Passing this test is awarded with **1 mark**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-while",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a817e49965eeb7bdfe0f741f97d64eb9",
     "grade": true,
     "grade_id": "cell-7af77f0d6f4631f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_array_almost_equal(one_hot_vector_encoding(np.array([1, 2, 0, 3])), \\\n",
    "                          np.array([[0,1,0,0],[0,0,1,0],[1,0,0,0],[0,0,0,1]]))\n",
    "assert_array_almost_equal(one_hot_vector_encoding(np.array([1,0,1,0])), \\\n",
    "                          np.array([[0,1],[1,0],[0,1],[1,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-console",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f66c5606fdd9a6fc7637d7f39750233",
     "grade": false,
     "grade_id": "cell-003f06c659f57f65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the cost function and gradient for the multinomial logistic regression in terms of two functions **multinomial_logistic_regression_cost_function** and **multinomial_logistic_regression_gradient**. As in the binary classification case, the arguments are the polynomial data matrix _data_matrix_ and weights that are now named _weight_matrix_. Instead of passing on labels as _outputs_ as in the binary case, you pass the one hot vector encoding representation _one_hot_vector_encodings_ as your third argument. Return the cost function value, respectively the gradient, following the mathematical formulas in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-participant",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "600a7996ddc8ca01b770f188dd70a96b",
     "grade": false,
     "grade_id": "cell-7cd27ba1d0741aa5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def multinomial_logistic_regression_cost_function(data_matrix, weight_matrix, one_hot_vector_encodings):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def multinomial_logistic_regression_gradient(data_matrix, weight_matrix, one_hot_vector_encodings):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-tradition",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc3c8e71a5e6630d0c8f3c7dc552baac",
     "grade": false,
     "grade_id": "cell-00d2f122e24939e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your implementation on the [glass dataset](https://archive.ics.uci.edu/ml/datasets/glass+identification); the dataset contains 9 attributes of 214 examples of glass that could belong to one of 7 classes. For more information on the dataset visit [this link](https://archive.ics.uci.edu/ml/datasets/glass+identification). The code in the following cell loads the dataset and stores the labels in a NumPy array _labels_ and the attributes in a NumPy array _inputs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-newcastle",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0af426b9a13873c43277b7ddccb7c311",
     "grade": false,
     "grade_id": "cell-0a4a886c2c1d13ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from data_loader import load_glass_data\n",
    "inputs, labels = load_glass_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-building",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3362fce90ac77f8724931d3d48f6f7ec",
     "grade": false,
     "grade_id": "cell-3a201b68167bc134",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Transform the labels _labels_ into a one hot vector representation with your function **one_hot_vector_encoding** and store your results in a NumPy array named _outputs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-valve",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2042baea783e754c61df5c30aa1fc85f",
     "grade": false,
     "grade_id": "cell-20f2dc736366e00a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-melissa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cc55b5e29c874e9e3676f9beab116aa",
     "grade": false,
     "grade_id": "cell-79d5214900766941",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following cell, write code that initialises a polynomial data matrix _data_matrix_ of degree one with the standardised inputs _inputs_ from the iris dataset. Define an objective function _objective_ with argument _weight_matrix_ based on the **multinomial_logistic_regression_cost_function** with fixed arguments _data_matrix_ and _one_hot_vector_encodings_. Repeat the same exercise to create a function _gradient_ based on **multinomial_logistic_regression_gradient**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-nirvana",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4941e5af793977a5f491731f6b6e3d06",
     "grade": false,
     "grade_id": "cell-8ff4f93ff34d251f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-fraction",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbebcdfb1ab476e4cd92dcc88a6a8dfa",
     "grade": false,
     "grade_id": "cell-e8dae6da05e0def8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Call gradient descent with the following cell to compute an _optimal_weight_matrix_ for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-refund",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "871875eaddb03a5157358214ab123254",
     "grade": false,
     "grade_id": "cell-338b63bd2fd2a723",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "initial_weight_matrix = np.zeros((data_matrix.shape[1], outputs.shape[1]))\n",
    "optimal_weight_matrix, objective_values = gradient_descent(objective, gradient, initial_weight_matrix, \\\n",
    "                                    step_size=3.9/(np.linalg.norm(data_matrix, 2) ** 2), \\\n",
    "                                    no_of_iterations=100000, print_output=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-flood",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5588b1b33435d6a9d322136c0dc49a0",
     "grade": false,
     "grade_id": "cell-5837ab1e096ee8d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write a function **multinomial_prediction_function** that turns your predicitons into labels. The function takes the arguments _data_matrix_ and _weight_matrix_ as inputs and returns a vector of labels with values in $\\{0, K - 1 \\}$ as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-indianapolis",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f025ce01bdcfc184e54e321ce0c750f9",
     "grade": false,
     "grade_id": "cell-6d5569f090b286ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def multinomial_prediction_function(data_matrix, weight_matrix):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-protocol",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65ebbc6476d929a736457102368150bc",
     "grade": false,
     "grade_id": "cell-312c928f9a7ef0bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The correct classification accuracy is awarded **4 marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-scottish",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40ca44dc158da3423c0e72694c9d822b",
     "grade": true,
     "grade_id": "cell-44b84027b758d175",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The classification accuracy for the glass dataset is {p} %.\".format(p = 100 * \\\n",
    "        classification_accuracy(labels, multinomial_prediction_function(data_matrix, optimal_weight_matrix))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-quality",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ba4d2385e007757a4d7b5d2f15f65b9",
     "grade": false,
     "grade_id": "cell-f430b21ef5a69b3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Two layers neural network for multiclass classification**\n",
    "\n",
    "In the last part of this section you are asked to improve the classification accuracy of multinomial logistic regression by considering a convolutional neural network with $L = 2$ layers. All layers have the same activation function which is given by a softmax function applied to an affine-linear transformation. Namely, we define\n",
    "\\begin{equation*}\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "Z^{(\\ell)} &=  \\widetilde{X}^{(\\ell-1)}W^{(\\ell)},\\\\\n",
    "X^{(\\ell)} &=  \\mathrm{softmax}\\left(Z^{(\\ell)}\\right)\n",
    "\\end{array}\n",
    "\\right.,\n",
    "\\label{eq:nn_model} \\tag{1}\n",
    "\\end{equation*}\n",
    "for $\\ell=1,\\ldots,L$, where $X^{(0)}$ is a mathematical representation of _inputs_ and tilde is introduced to denote an augmented matrix, i.e. the one with artificial column of ones inserted at the beginning of a matrix. In the above weight matrices $W^{(\\ell)}$ have dimensions $\\left( d_{\\ell} + 1 \\right)\\times d_{\\ell+1}$ with $d_1 =d_2=\\ldots=d_L = d$ and $d_{L+1} = K$, with $K$ being a number of class labels in the original classification problem. \n",
    "\n",
    "Let $\\mathbf{W} = \\left\\{W^{(\\ell)}\\right\\}_{\\ell = 1}^L$ be a full set of parameters defining the model. Your task in this section is to find an optimal values of parameters $\\mathbf{W}$ such that the cost function\n",
    "$$\n",
    "L\\left(\\mathbf{W}\\right) = \n",
    "\\sum\\limits_{i=1}^s \\log\\left(\\sum\\limits_{j=1}^K\n",
    "\\mathrm{e}^{Z^{(L)}_{i,j}}\\right)\n",
    "-\n",
    "\\sum\\limits_{i=1}^s\\sum\\limits_{j=1}^K\n",
    "\\mathbf{1}_{y_i = j} Z^{(L)}_{i,j}.\n",
    "$$\n",
    "is minimised.\n",
    "\n",
    "The optimisation problem is set to be solved by using the gradient descent method. This involves a backpropagation approach to a calculation of the gradient $\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d}\\mathbf{W}}$ (see lecture notes). To help you with the problem, we provide a series of results on an interconnection between different derivatives. Every derivative here is thought as a gradient and is written in the form of a corresponding size matrix. For example,\n",
    "the derivative $\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d}W^{(1)}}$ should be thought as a gradient of the cost function $L\\left(\\mathbf{W}\\right)$ with respect to the arguments $W^{(1)}_{i,j}$ that is written as a matrix of size $\\left(d+1\\right)\\times d$. In what follows, we denote a matrix $M$ with the first row removed as $\\widehat{M}$ and also write $\\mathrm{OHV}$ for a one hot vector representation of input data.\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{array}{rcl}\n",
    "\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d} Z^{(\\ell)}}&=& \n",
    "\\begin{cases}\n",
    "\\mathrm{softmax}\\left(Z^{(L)}\\right) - \n",
    "\\mathrm{OHV},& \\ell = L,\\\\\n",
    "X^{(\\ell)}\\odot\\left[\n",
    "\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d} X^{(\\ell)}}\n",
    "- \\Sigma\\left(X^{(\\ell)}\\odot\n",
    "\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d} X^{(\\ell)}} \\right)\n",
    "\\right]\n",
    ",& \\ell < L\n",
    "\\end{cases}\n",
    "\\\\\n",
    "\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d} X^{(\\ell)}} &=& \\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d} Z^{(\\ell+1)}}\\cdot \\left(\\widehat{W}^{(l+1)}\\right)^{\\top}\n",
    "\\\\\n",
    "\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d} W^{(\\ell)}} &=& \n",
    "\\left(\\widetilde{X}^{(\\ell-1)}\\right)^{\\top}\\cdot\n",
    "\\frac{\\mathrm{d}L\\left(\\mathbf{W}\\right)}{\\mathrm{d} Z^{(\\ell)}}\n",
    "\\end{array}\n",
    "},\n",
    "$$\n",
    "where for any matrix $M$ we define $\\Sigma\\left(M\\right)$ as a matrix of the same dimensions as $M$ but with every matrix element swapped with a row-sum of matrix elements of matrix $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-mistake",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d78e57214574c7382de2ce2665882d5",
     "grade": false,
     "grade_id": "cell-48718753c1ef6e16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your first task would be to implement the cost function and the gradient in terms of two functions **nn\\_multinomial\\_logistic\\_regression\\_cost\\_function** and **nn\\_multinomial\\_logistic\\_regression\\_gradient**. \n",
    "Unlikely to the case of a simple multinomial classification, we can not evaluate the cost function and the gradient straightaway. Therefore you first need to implement a function that evaluates the values of variables $X^{(\\ell)}$ and $Z^{(\\ell)}$ on all hidden layers $\\ell = 1,\\ldots,L$. Define a function **nn\\_model\\_evaluation** with arguments _data\\_matrix_, _weight\\_matrix_ that evaluates and returns a numpy array of the model values on all hidden layers. (see (1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-synthesis",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce25101bc8c45adc4718b39bd7014f85",
     "grade": false,
     "grade_id": "cell-d07d7064cf3b98b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def nn_model_evaluation(data_matrix, weight_matrix):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-steel",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8723686b7aad3a73851a6eba7d0ed07a",
     "grade": false,
     "grade_id": "cell-78a8ef72d2c71db2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we are ready to implement the cost function and the gradient in terms of two functions **nn\\_multinomial\\_logistic\\_regression\\_cost\\_function** and **nn\\_multinomial\\_logistic\\_regression\\_gradient**. The functions should have the same arguments and output as the ones used in simple multinomial classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-government",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8f30a79039f113b4a816e94c8942963",
     "grade": false,
     "grade_id": "cell-ef25ba5b74118258",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def nn_multinomial_logistic_regression_cost_function(data_matrix, weight_matrix, one_hot_vector_encodings):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def nn_multinomial_logistic_regression_gradient(data_matrix, weight_matrix, one_hot_vector_encodings):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-floor",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ca8d5f912dbb6e2453a39b3a55c9e4d",
     "grade": false,
     "grade_id": "cell-c98b6601d57d9e4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following cell, write code that initialises a data matrix _data_matrix_ with the standardised inputs _inputs_ from the glass dataset. Define an objective function _objective_ with argument _weight_matrix_ based on the **nn\\_multinomial_logistic_regression_cost_function** with fixed arguments _data_matrix_ and _one_hot_vector_encodings_. Repeat the same exercise to create a function _gradient_ based on **nn\\_multinomial_logistic_regression_gradient**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-blackjack",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a85e19a324f1b9635b28defd2c5524",
     "grade": false,
     "grade_id": "cell-17501954c243af4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-minister",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dce69462055c32c212a6816cc6b0bb90",
     "grade": false,
     "grade_id": "cell-e94e0ad959cd8a54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Call gradient descent with the following cell to compute an _optimal_weight_matrix_ for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-winter",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e492af9132b7ef94336a088df1947c82",
     "grade": false,
     "grade_id": "cell-21e1077bbe91ec94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "layers_number = 2\n",
    "initial_weight_matrix = np.empty(layers_number, dtype = np.ndarray)\n",
    "for weight_pos in range(layers_number):\n",
    "    if (weight_pos < layers_number-1):        \n",
    "        initial_weight_matrix[weight_pos] = np.zeros((data_matrix.shape[1]+1,inputs.shape[1]))\n",
    "        np.fill_diagonal(initial_weight_matrix[weight_pos],1)\n",
    "    else:\n",
    "        initial_weight_matrix[weight_pos] = np.zeros((data_matrix.shape[1]+1,outputs.shape[1]))\n",
    "            \n",
    "optimal_weight_matrix, objective_values = gradient_descent(objective, gradient, initial_weight_matrix, \\\n",
    "                                    step_size=3.9/(np.linalg.norm(data_matrix, 2) ** 2), \\\n",
    "                                    no_of_iterations=10000, print_output=100001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-battery",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20acde3576a5b84ec6733650bbeb3208",
     "grade": false,
     "grade_id": "cell-8983c628020a776e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write a function **nn\\_multinomial_prediction_function** that turns your predicitons into labels. The function takes the arguments _data_matrix_ and _weight_matrix_ as inputs and returns a vector of labels with values in $\\{0, K - 1 \\}$ as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-publicity",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a40abd894cd207951e8c0e0be9c7764",
     "grade": false,
     "grade_id": "cell-e9cc52f13c5936c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def nn_multinomial_prediction_function(data_matrix, weight_matrix):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-highland",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b5005cdfc17a01269e5bfb17b55b1b9",
     "grade": false,
     "grade_id": "cell-b3ed31b444cbac1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The correct classification accuracy is awarded **4 marks**. The total number of possible marks in this section is **13 marks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-sheriff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "375c4470f7f77654cdace6854bc2e880",
     "grade": true,
     "grade_id": "cell-0b1ad5d0786ba25f",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"The classification accuracy for the glass training set is {p} %.\".format(p = 100 * \\\n",
    "        classification_accuracy(labels, nn_multinomial_prediction_function(data_matrix, optimal_weight_matrix))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-assurance",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94151b78d197c89b87ea902f0f2f7e5d",
     "grade": false,
     "grade_id": "cell-d3efebde2f313811",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The total number of possible marks in the first part is **40 marks**."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
